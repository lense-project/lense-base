\section{Model}
\label{sec:model}

The central problem is to determine which queries $q_1, q_2, \dots$ to issue on
any example and when.  We create a stochastic game where ...

%In this section, we describe how we model output predictions and query responses.
% A general model family - conditional exponential models
% Incorporating feedback as "measurements" as per Percy
% Error model - defer investigation to a later section.
% Querying for an optimal measurement - defer asynchrony to a later section.
% Learning given feedback 

%\pl{Also, the measurement stuff gets kind of abstract quickly, so have good running examples
%and try to minimize notation; don't go for generality if you don't need it}

%Our goal, given an existing model, is to identify labels where we lack confidence, query crowd works for measurements if needed and incorporate the resultant responses back into our model.
\paragraph{Prediction model.}
We consider the family of conditional exponential models, a popular class of models that include logistic regression and conditional random fields.
Let $\bx$ be a given input, then the labels $\by = y_1, \ldots, y_n \in \{1, \dots, L\}$ are generated by the following conditional distribution:
\begin{align*}
  \p(\by \given \bx) 
  &= \exp( \theta^\top \phi(\bx, \by) - A(\theta; \bx)),
\end{align*}
where $\theta$ are the model parameters,
$\phi(\bx, \by)$ are arbitrary features of the input and labels and 
$A(\theta; \bx)$ is the conditional log-normalizer.
We assume that the model has low treewidth (e.g.\ $\phi$ factorizes over the labels $\by$) or otherwise admits efficient marginal computation.

For example, the model in \figureref{crf} is a linear-chain conditional random field. The input is the sequence of words in the tweet and the output is a label in the set \scnone, \scres, \scloc{} and \scper. Marginal inference can be efficiently computed using the Viterbi algorithm.

%Conventionally, we are given a training dataset $\sD = \{\bx_i, \by_i\}$ and can learn $\theta$ by optimizing the convex log-likelihood objective $\sL(\theta) = \sum_{t=1}^T \log \p(\by\oft{t} \given \bx\oft{t})$.
%In our setting, however, we do not observe the gold labels $\by$. 
%Instead, we can ask the crowd to provide a ``measurement'' for some subset of the labels.
%Let $\Sigma = \{\sigma_i\}$ be the set of possible measurements we can ask the crowd for and 
%let $\by_\sigma \subseteq \by$ be the subset of labels queried.

\paragraph{Response model.}
Let $q \in \{1, \ldots, n\}$ be a query on for the label $y_q$.
We model the response, $r$, with an exponential measurement model:
\begin{align*}
  p_\beta(r \given x, y, q) 
  &\propto \exp \left( \beta^\top\psi(\bx, y_q, r) \right),
\end{align*}
where $\beta$ and $\psi$ are extra parameters and features for the human error model. 
%The choice of an exponential model allows us to simply include measurements as an additional factor.
\figureref{crf}(c) shows the original graph with additional measurement nodes.
A simple human error model is to return the true label with probability $1-\epsilon$ and a random label otherwise.
In our running example, some classes, e.g.\ $\textsc{none}$, are more easily identified than others: in this setting responses can be modeled to be sampled from a confusion matrix.

Finally, we model delay to be drawn from a Gamma distribution: $\tau \sim \Gamma$\footnote{We assume here for simplicity that the response delays are independent of the input and which label is being queried. The model can easily be generalized to incorporate these settings.}.
\ac{The gamma is missing parameters.}
Note that the total time taken on a prediction, $t$, depends not only on how many requests are made, but also when they are scheduled.
%We study the problem of how to best schedule multiple requests in \sectionref{async}.

Next, we describe how we use our models to predict labels and learn from partial feedback.

\paragraph{Making predictions.}
Given parameters $\theta, \beta$ and responses $r_1, \ldots, r_m$, our model makes predictions using maximum likelihood:
$\byt \given \bx, r_1, \ldots r_m = \argmax_{\by} \p(\by \given \bx, r_1, \ldots r_m)$.

\paragraph{Learning from responses.}
Recall that we do not have gold labels for our data, but only noisy measurements: we do not have supervised examples to learn from. 
As a simple heuristic, we use the output from our model as gold labels and update our parameters $\theta$ periodically.  
We consider the response parameters $\beta$ to be fixed a priori.
The time delay parameters can easily be estimated from the observed response delays.
%In future work, we plan to explore using (online) expectation-maximization to jointly learn parameters for our model and the human error model in an unsupervised fashion.

\paragraph{Computing expected utility.}

\ac{Text}
We cast this problem in the Bayesian decision theoretic framework: our objective is to maximize our expected utility under our current model,
$\p(\by \given \bx, \br)$:
\begin{align*}
  u &= \E_{\by \sim \p(\cdot \given \bx, \br)}[1 - \ell(\by, \byt) + C(\bq, t)].
\end{align*}

