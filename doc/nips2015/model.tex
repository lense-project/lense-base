\section{Model}
\label{sec:model}

% Define game top-down
The central technical challenge in on-the-job training
is to determine which queries $q_1, q_2, \dots$ to issue on an input $\bx$
any example and when.  For this, we appeal to Bayesian decision theory.
We define a stochastic game with two players, the system and the crowd.
To get started, consider the simplified game tree in \figureref{piano-roll}(right).
At the root, the system chooses an query $q \in \{1, \dots, n\}$ to label a position,
and then the crowd responds with $r \in \{ \scper{}, \scloc{}, \scnone{} \}$.
Each leaf of the game tree represent a \emph{utility} $U(q, r)$ of that outcome.
The \emph{value} of the game is the maximum expected utility:
\begin{align}
  V^* = \max_q \E_{p(r \mid \bx, q)}[U(q, r)],
\end{align}
and the \emph{optimal policy} is to choose the action $q$ that attains $V^*$.
Let's look at the example more intuitively:
querying one of the end positions ($q = 1$ or $q = 3$),
is less informative than choosing the middle position ($q = 2$),
assuming the model propagates information between adjacent positions.
Indeed, the expected utilities with a uniform distribution over $r$
are $0.7$, $0.8$, and $0.7$, respectively, and so $q = 2$ is the optimal action.

Note that computing the $V^*$ is only \emph{simulating} possible futures,
not actually querying the crowd.  The simulation is based on the transition
probabilities $p(r \mid \bx, q)$ and the utilities $U(q, r)$, which are
based on a Bayesian model that connects input, output, responses, and time delays.

\paragraph{Bayesian model.}

We now will define our full model.
Formally, given input $\bx$ and queries $\bq = (q_1, \dots, q_k)$ issued at times $\bs = (s_1, \dots, s_k)$,
we define a distribution over the output $\by$, responses $\br = (r_1, \dots, r_k)$
and response times $\bt = (t_1, \dots, t_k)$ as follows:
\begin{align}
%p(\by, \br, \bt \mid \bx, \bq) \eqdef \p(\by \given \bx) \prod_{i=1}^k \presp(r_i \mid \bx, \by, q_i) \ptime(t_i \mid \bx, \by, q_i, s_i).
p(\by, \br, \bt \mid \bx, \bq) \eqdef \p(\by \given \bx) \prod_{i=1}^k \presp(r_i \mid \by, q_i) \ptime(t_i \mid s_i).
\end{align}
The three components are as follows:
First, $\p(\by \given \bx)$ is the \emph{prediction model},
which in our case is a standard linear-chain CRF.
Second, $\presp(r \given \by, q)$ is the \emph{response model},
which governs the crowd's probability of producing a response $r$ to a given a query when the true answer is $\by$.
Ideally, this would be $1$ iff $r = y_q$, but the crowd is noisy,
so we base $\presp$ off of an estimated confusion matrix over labels.
Finally, $\ptime(t \given s)$ is the \emph{time delay model},
which governs how long a given query $q$ will take.
While in reality $t$ depends on many factors including the input $\bx$,
we let $t - s$ be a Gamma distribution with globally fixed parameters.

% Doing things with the model
Given this full model, we can compute transition probabilities such as $p(r \mid \bx, q)$
simply by marginalizing out $\by$ in the CRF.
If we had already made one query $q_1$ and and gotten a response $r_1$,
we can incorporate the evidence, which will propgate through the CRF
and inform the distribution over possible responses $r_2$ for the next query $q_2$:
$p(r_2 \mid \bx, q_1, r_1, q_2)$.

% Time
The temporal aspect of the model also allows for interesting possibilities
and is important for handling asynchronous queries and responses.
Suppose we made a query $q_1$ at time $s_1$ but have not yet gotten response $r_1$.
We might still want to ask for various probabilities \emph{at time} $t$,
which involves integrating over possible future responses $r_1$ and response times $t_1$.
Formally, define $r_i[t]$ to be the response at time $t$, which is equal to $r_i$ if $t_i \le t$
or $\emptyset$ if $t_i > t$.
Then we could ask about the probability of a response $r_2$ at time $t$,
which integrates over the possibility of having received $r_1$ or not:
\begin{align}
p(r_2[t] \mid \bx, q_1, q_2) = p(t_1 \le t \mid s_1) p(r_2[t] \mid \bx, q_1, r_1, q_2) + p(t_1 > t \mid s_1) p(r_2[t] \mid \bx, q_2).
\end{align}

\paragraph{Utility.}

The Bayesian model defines the full dynamics of the game through various
conditioning and marginalization operations.
We now define the utility of the game at time $t$, which is the expected
accuracy according to the model's best guess of $\by$ at time $t$
(which would be the negative entropy of this distribution if we replaced
accuracy with log loss), plus a penalty for time and money.
Formally, the utility is defined as follows:
\begin{align}
  U_t(\bq, \bs, \br, \bt) \eqdef \E_{p(\by \given \bx, \bq, \bs, \br[t], \bt)}[\accuracy(\by, \byt) - \alpha m k - \beta t].
\end{align}
Here we are measuring the accuracy with a penalty for spending $m$ cents per $k$ queries
and taking $t$ units of time.
Note that we are only conditioning on the responses $\br[t]$ available at time $t$.

%\paragraph{Prediction model.}
% PL: form isn't relevant here since later we use other types of models anyway
%Assume our model
%We consider the family of conditional random fields
%exponential models, a popular class of models that include logistic regression
%and conditional random fields.
%Let $\bx$ be a given input, then the labels $\by = y_1, \ldots, y_n \in \{1,
%\dots, L\}$ are generated by the following conditional distribution:
%\begin{align*}
%  \p(\by \given \bx) 
%  &\propto \exp(\theta^\top \phi(\bx, \by)),
%\end{align*}
%where $\phi(\bx, \by)$ are features
%and $\theta$ are model parameters.
%In this paper, $\p(\by \given \bx) We assume that inference is efficient, which it is
%for our chain-structured models.
%(e.g.\ $\phi$ factorizes over the
%labels $\by$) or otherwise admits efficient marginal computation.

%For example, the model in \figureref{crf} is a linear-chain conditional random
%field. The input is the sequence of words in the tweet and the output is a
%label in the set \scnone, \scres, \scloc{} and \scper. Marginal inference can
%be efficiently computed using the Viterbi algorithm.

%Conventionally, we are given a training dataset $\sD = \{\bx_i, \by_i\}$ and can learn $\theta$ by optimizing the convex log-likelihood objective $\sL(\theta) = \sum_{t=1}^T \log \p(\by\oft{t} \given \bx\oft{t})$.
%In our setting, however, we do not observe the gold labels $\by$. 
%Instead, we can ask the crowd to provide a ``measurement'' for some subset of the labels.
%Let $\Sigma = \{\sigma_i\}$ be the set of possible measurements we can ask the crowd for and 
%let $\by_\sigma \subseteq \by$ be the subset of labels queried.

%\paragraph{Response model.}
%Let $q \in \{1, \ldots, n\}$ be a query on for the label $y_q$.
%We model the response, $r$, with an exponential measurement model:
%\begin{align*}
%  p_\beta(r \given x, y, q) 
%  &\propto \exp \left( \beta^\top\psi(\bx, y_q, r) \right),
%\end{align*}
%where $\beta$ and $\psi$ are extra parameters and features for the human error model. 
%%The choice of an exponential model allows us to simply include measurements as an additional factor.
%\figureref{crf}(c) shows the original graph with additional measurement nodes.
%A simple human error model is to return the true label with probability $1-\epsilon$ and a random label otherwise.
%In our running example, some classes, e.g.\ $\textsc{none}$, are more easily identified than others: in this setting responses can be modeled to be sampled from a confusion matrix.
%
%Finally, we model delay to be drawn from a Gamma distribution: $\tau \sim \Gamma$\footnote{We assume here for simplicity that the response delays are independent of the input and which label is being queried. The model can easily be generalized to incorporate these settings.}.
%\ac{The gamma is missing parameters.}
%Note that the total time taken on a prediction, $t$, depends not only on how many requests are made, but also when they are scheduled.
%%We study the problem of how to best schedule multiple requests in \sectionref{async}.
%
%Next, we describe how we use our models to predict labels and learn from partial feedback.

%\paragraph{Making predictions.}
%Given parameters $\theta, \beta$ and responses $r_1, \ldots, r_m$, our model makes predictions using maximum likelihood:
%$\byt \given \bx, r_1, \ldots r_m = \argmax_{\by} \p(\by \given \bx, r_1, \ldots r_m)$.
%
%\paragraph{Learning from responses.}
%Recall that we do not have gold labels for our data, but only noisy measurements: we do not have supervised examples to learn from. 
%As a simple heuristic, we use the output from our model as gold labels and update our parameters $\theta$ periodically.  
%We consider the response parameters $\beta$ to be fixed a priori.
%The time delay parameters can easily be estimated from the observed response delays.
%%In future work, we plan to explore using (online) expectation-maximization to jointly learn parameters for our model and the human error model in an unsupervised fashion.
%
%\paragraph{Computing expected utility.}
%
%\ac{Text}
%We cast this problem in the Bayesian decision theoretic framework: our objective is to maximize our expected utility under our current model,
%$\p(\by \given \bx, \br)$:
%\begin{align*}
%  u &= \E_{\by \sim \p(\cdot \given \bx, \br)}[1 - \ell(\by, \byt) + C(\bq, t)].
%\end{align*}

