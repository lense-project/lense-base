\section{Problem formulation}
\label{sec:model}

\begin{figure}[t]
  \begin{centering}
  \includegraphics[width=1.0\textwidth]{figures/intro-banner.pdf}
  \end{centering}
  \caption{
    Named entity recognition on tweets in on-the-job learning.
    %(1) The system first runs a
%pre-trained model, discovers that the token ``George'' is ambiguous, and then
%asks a human for a label. The human label is returned in a few seconds,
%incorporated into the model, and the model then decides it has enough
%information to turn in a classification.
}
\label{fig:crf}
\end{figure}

%\afterpage{\noindent
%\begin{figure}
%  \begin{centering}
%    \begin{subfigure}[b]{0.58\textwidth}
%      \includegraphics[width=\textwidth]{figures/piano-roll.pdf}
%      \caption{Structured prediction behavior over time}
%    \end{subfigure}
%    \hfill
%    \begin{subfigure}[b]{0.38\textwidth}
%      \includegraphics[width=\textwidth,height=0.23\textheight,keepaspectratio]{figures/single-move.pdf}\\[1.7ex]
%      \caption{Single-query game tree}
%    \end{subfigure}
%  \end{centering}
%\caption{Example behavior while running structure prediction on the tweet ``Soup on George str.''
%We omit the \scres{} from the game tree for visual clarity.
%}
%\label{fig:game-tree}
%\end{figure}
%}

% Define structured prediction
Consider a structured prediction problem from input $\bx = (x_1, \dots, x_n)$ to output $\by = (y_1, \dots, y_n)$.
For example, for named-entity recognition (NER) on tweets,
$\bx$ is a sequence of words in the tweet (e.g., \nl{on George str.})
and $\by$ is the corresponding sequence of labels (e.g., \scnone{} \scloc{} \scloc{}).
The full set of labels of \scper{}, \scloc{}, \scres{}, and \scnone{}.

% Basic setting
In the \emph{on-the-job learning} setting, inputs arrive in a stream.
On each input $\bx$,
we make zero or more queries $q_1, q_2, \dots$ on the crowd to obtain labels
(potentially more than once)
for any positions in $\bx$.
The responses $r_1, r_2, \dots$ come back asynchronously,
which are incorporated into our current prediction model $p_\theta$.
\figureref{game-tree}~(left) shows one possible outcome:
We query positions $q_1 = 2$ (\nl{George}) and $q_2=3$ (\nl{str.}).
The first query returns $r_1 = \scloc$,
upon which we make another query on the the same position $q_3 = 3$ (\nl{George}),
and so on.
When we have sufficient confidence about the entire output,
we return the most likely prediction $\hat \by$ under the model.
Each query $q_i$ is issued at time $s_i$ and the response comes back at time $t_i$.
Assume that each query costs $m$ cents.
Our goal is to choose queries to maximize accuracy, minimize latency and cost.

% More intuition / connections
We make several remarks about this setting:
First, we must make a prediction $\hat \by$ on each input $\bx$ in the stream,
unlike in active learning, where we are only interested in the pool or stream of examples
for the purposes of building a good model.
% PL: though active learning will query hard examples too
%Second, we evaluate on $\accuracy(\by, \byt)$ against the true label sequence $\by$
%(on named-entity recognition, this is the F$_1$ metric),
%but $\by$ is never actually observed---the only feedback is via the responses,
%like in partial monitoring games \citep{cesabianchi06regret}.
%Therefore, we must make enough queries to garner sufficient confidence
%(something we can't do in partial monitoring games)
%on each example from the beginning.
Second, the responses are used to update the prediction model, like in online learning.
This allows the number of queries needed (and thus cost and latency) to decrease over time
without compromising accuracy.

% VKeenon
% As a motivating example, imagine an automated trading firm.
% To the consternation of our hypothetical firm, a news article comes out describing how every time an Anne Hathaway (actress) movie is released, all the positive sentiment co-occurring in documents with ``Hathaway" tokens leads to a bump in the Berkshire Hathaway (investment firm) stock price.
% To their embarrassment, the firm realizes that their algorithms are partially responsible for this phenomenon.
% As a fix, they decide they need to deploy a system to do named entity recognition to disambiguate between tokens referring to \scper{}, companies \todo{}, and \scnone{}.
% They'd like very high accuracy and rapid labelling times, but without first labeling a large quantity of historical data. They're willing to pay some money for increased real-time accuracy, but they wouldn't like to be paying forever.
% They decide to turn to \emph{on-the-job learning}.
% 
% Consider a structured prediction problem from input $\bx = (x_1, \dots, x_n)$ to output $\by = (y_1, \dots, y_n)$,
% where it is possible to query humans about their noisy opinions of the value of any $y_i \in \by$
% at the expense of some money and time.
% For our firm running NER, $\bx$ is a sequence of words in the newswire (e.g., \nl{Hathaway smiles on red carpet})
% and $\by$ is the corresponding sequence of tags (e.g., \scper{} \scnone{} \scnone{} \scnone{}).
% 
% % Basic setting
% In the \emph{on-the-job learning} setting, inputs arrive in a stream.
% On each input $\bx$, we can make queries $q_1, q_2, \dots$ to the crowd about tokens $y_i \in \by$.
% The responses $r_1, r_2, \dots$ come back with some delay after their corresponding query was made.
% Once we integrate those responses into our beliefs, we return our MAP estimate of $\hat \by$, and the game ends.
% 
% We could model this as a synchronous sequential decision game, where the game player can choose to make a single query $q_j$, then must wait for the response $r_j$, and then can play again.
% This approach, though simple, fails to take advantage of the possibility of querying multiple crowd workers in parallel, and thus fails to hide much of the latency of their responses.
% Instead, we allow the system to play \emph{asynchronously}, which means after issuing a query $q_j$, the system is immediately asked what it would like to do next, and may choose to issue query $q_{j+1}$.
% In order to receive one of the response $r_j, r_{j+1}, \dots$, the system must explicitly choose to wait for the next event in the game, which puts the player to sleep until the next event takes place.
% This means many gameplay decisions are made with queries ``in-flight,'' which increases decision making complexity, but allows the system to dramatically reduce classification latency by issuing multiple queries simultaneously.
% 
% % We model this as a game played with the system and a crowd, where the goal of the system is to maximize utility, and the goal of the crowd to try to be helpful, but occasionally make mistakes.
% % We model this as a \emph{system-initiative} game, which means it is always the turn of the system to make another move (with no time delay between moves) unless the system explicitly decides to wait, in which case the crowd may make a single response (and incur some delay) before the system gets to play again.
% 
% % More intuition / connections
% We make several remarks about this setting:
% First, we must make a prediction $\hat \by$ on each input $\bx$ in the stream,
% unlike in active learning, where we are only interested in the pool or stream of examples
% for the purposes of building a good model.
% % PL: though active learning will query hard examples too
% Second, we evaluate on $\accuracy(\by, \byt)$ against the true tag sequence $\by$
% (on named-entity recognition, this is the F$_1$ metric),
% but $\by$ is never actually observed---the only feedback is via the responses,
% like in partial monitoring games \citep{cesabianchi06regret}.
% Therefore, we must make enough queries to garner sufficient confidence
% (something we can't do in partial monitoring games)
% on each example from the beginning.
% Finally, the responses are used to update the prediction model, like in online learning.
% This allows the number of queries needed (and thus cost and latency) to decrease over time
% without compromising accuracy.

%We receive a stream of inputs $\bx\oft1, \bx\oft2, \ldots, \bx\oft N$ with corresponding {\em unobserved\/} true output $\by\oft1, \by\oft2, \ldots, \by\oft N$ that we would like to predict.

% PL: too much detail about strategy
% at this point, just the get dynamics of the environment set up.
%Let us make our problem setting concrete with an example, depicted in \figureref{piano-roll}.
%We receive an input ``Soup on George str \#Katrina'' ($\bx$) and must produce
%an output ($\byt$) that labels words with the tags.
%Initially, our model is uncertain about both ``George'' and ``str''.
%We first query the crowd for a label on ``George'' ($q_1$) and then for a label on ``str'' ($q_2$). 
%After some time, the crowd responds with the label \scloc{} on both ``George'' ($r_1$) and ``str'' ($r_2$).
%At this point, the model is confident in its labeling, and we can turn in its
%prediction $\byt$.
%By querying the crowd queries $\bq = (q_1, q_2)$, we are not only able to
%produce a more accurate output, but can also use the responses $\br = (r_1,
%r_2)$ to train a better model.

%Of course, querying the crowd also incurs a cost for the queries as well as a
%time delay, $t$: $C(\bq, t)$ \pl{give example numbers that we used}

%In general, we want to maximize our accuracy by making queries while trading
%off the cost and time delay introduced.

% We cast this problem in the Bayesian decision theoretic framework: our objective is to maximize our expected utility under our current model,
% $\p(\by \given \bx, \br)$:
% \begin{align*}
%   u &= \E_{\by \sim \p(\cdot \given \bx, \br)}[1 - \ell(\by, \byt) + C(\bq, t)].
% \end{align*}

%\ac{Probably should talk more about training.} % PL: not really

%We receive a stream of inputs $\bx\oft1, \bx\oft2, \ldots, \bx\oft N$ with corresponding {\em unobserved\/} true output $\by\oft1, \by\oft2, \ldots, \by\oft N$ that we would like to predict.
%For each input $\bx$, we may query the crowd several times. Let $Q = \{q_1, \ldots, q_m\}$ be the set of queries.
%Finally, we observe responses $R = \{r_1, \ldots r_m\}$ to our queries after some time $t$.
%Using the information from these queries, our model makes the prediction, $\byt\oft{t}$.
%Our goal is to maximize the accuracy, trading off cost and latency as specified by a given objective function.
%
%More formally, suppose the output $\by\oft{t}$ has $n$ parts: $\by\oft{t} = y\oft{t}_1, \dots, y\oft{t}_n$.
%Let $q\oft{t} \in \{1, \ldots, n\}$ be a request for the label $y\oft{t}_q$,
%let $Q\oft{t} = (q\oft{t}_1, \dots, q\oft{t}_m)$ be a sequence of queries made on the $t$-th input and
%let $\tau\oft{t}$ be the time taken to make the prediction $\byt\oft{t}$. 
%We would like to minimize the cumulative loss, 
%following objective:
%\begin{align}
%  \sL &= \sum_{t=1}^T \ell_{\rmclass}(\by\oft{t}, \byt\oft{t}) + C(Q\oft{t}, \tau\oft{t}), \label{eqn:objective}
%\end{align}
%where $\ell_{\rmclass}$ is a given misclassification loss function, e.g.\ the Hamming loss, and $C$ is a given cost function.
%\ac{Concern: by using the cumulative loss, is there an expectation that we will ``model'' input and optimize for the future?}
%
%We now describe our choice of models for prediction, human error and latencies and return to optimizing \equationref{objective} in \sectionref{async}.
%
