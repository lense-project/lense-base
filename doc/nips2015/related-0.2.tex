\section{Related Work}
\label{sec:related}

The on-the-job learning setting brings together two orthogonal ideas: \textbf{1)} learning classifiers in the presence of streaming partially observed data, and \textbf{2)} querying oracles {\em during classification} for additional certainty.

\paragraph{1) Learning classifiers in the presence of streaming partially observed data:}

Online Active learning\footnote{We refer the readers to~\cite{settles2010active} for a survey of active learning methods and variants.} is a popular approach to minimize the labeled data required to train a classifier in the presence of data that can only be observed {\em without noise after classification} at some cost.
Several authors in the active learning community have considered using crowd workers as a noisy oracle~\cite{donmez2008proactive,golovin2010near,yan2011active,vijayanarasimhan2014large}.
Although we also use crowd workers, on-the-job learning is allowed to query at test time and must trade off cost, latency and accuracy while doing so, and does not get to observe noiseless data.

\paragraph{2) Querying oracles during classification for additional certainty:}

Active classification~\cite{greiner2002learning,chai2004test,esmeir2007anytime} asks what is the {\em most informative feature\/} to measure at test time.
Existing active classification algorithms rely on having a fully labeled dataset which is used to learn a static policy for when certain features should be queried, which does not change at test time.
One could view our queries as high-informative features, however our work differs in two respects: we never get to actually observe the true labels, and our system improves itself at test time by learning a stronger model.

There is little existing work on querying a subset of the labels within a single structured output problem.
Angeli et al.~\cite{angeli2014combining} identify instances to label within a cluster of examples in a distantly supervised setting. While this choice was a subset of the labels in the graphical model, interactions between other labels in cluster were not considered.
Liang et al.~\cite{liang09measurements} introduced the measurement framework and studied the problem of active selection of measurements in the active learning setting.

Using crowd workers to assist labeling tasks is an area of active research within the HCI community.
\textit{Flock}~\cite{cheng2015flock} first crowdsources the identification of features for an image classification task, and then asks the crowd to annotate examples.
The system learns to classify images using a decision tree based on the features identified by the crowd.
As a consequence, the system always relies on humans to provide features and there is no transfer of knowledge from humans to a machine learning model as in on-the-job training.
In another line of work, \textit{TurKontrol}~\cite{dai2010decision} models individual crowd worker reliability to optimize the number of human votes needed to achieve confident consensus using a POMDP\@.

\paragraph{Combining 1 \& 2:}

\todo{Spot check this. This is probably the wrong pitch here?}
\textit{Legion AR}~\cite{lasecki2013real} is the only system that the authors are aware of that makes a serious effort to combine querying during test time with a model that is learning in an online fashion. While groundbreaking, Legion AR did not reach the full potential of the setting. It makes no effort to use noisy queries to directly update beliefs, instead relying on a ``query-intermediate'' system to perform a max-vote to get data that is then treated as noiseless. This means that Legion AR is unable to perform the kinds of adaptive gameplaying that we demonstrate to be successful in structured prediction: instead it chooses to either accept or reject its model hypothesis, and in the rejection case to receive expensive over-labeled data as ground truth.

%This work tries to relax the traditional assumptions in active learning that the oracle is infallible and has no economic cost.
%Some of this work is directly motivated by applications to crowd-sourcing platforms that we investigate.
%WHY DIFFERENT?

% Bayesian priors we use not.
%Finally Bayesian active learning (\cite{golovin2010near},~\cite{tong2000active}) allows us to incorporate a Bayesian prior over our data, and we'll use this as a foundation for our approach to solving the asynchronous behavior problem.

%We also model the reliability of workers though using an unsupervised model, similar to \findcite{crowd em}.
Finally, recent work has studied how to support real-time behavior with crowd workers~\cite{bernstein2011crowds,lasecki2013real} by hiring workers ``on retainer''.
We use the same retainer model to maintain a pool of real-time crowd workers with low response times.

% Using crowds to power decision making is not a new idea. Systems in this space that support real-time behavior include \textit{Adrenaline}~\cite{bernstein2011crowds} and \textit{Legion AR}~\cite{lasecki2013real}, which both use a system where crowds are recruited ``on-retainer'' in order to be available at a moments notice.
% We use the same retainer model to maintain a pool of real-time workers with low response times.
%Using artificial-intelligence-crowd hybrids for time-insensitive workflows has also been previously explored.
%It makes no effort to train a model to augment or take over from the workers, so costs remain constant over time.
%Empirical studies have shown that this is an effective method for managing complex workflows \cite{peng2011artificial}.
%Our work follows \cite{peng2010decision} in that we apply Decision Theory to the problem of when to query the crowd, but we train a model to take over for the workers over time, and we handle the additional real time response constraint.

%\ac{I omitted partial monitoring games because it seems to be covered in the algo section.}
%\paragraph{Partial monitoring games.}
%\noteb{This bullet point is actually to motivate that our problem is theoretically feasible.}
%Our evaluation metric is unique in the active learning space in that consider a loss we do not observe because we never receive true labels.
%By treating the measurements as partial feedback, our work can be theoretically modeled as a partial monitoring game\cite{cesabianchi06regret} and, in particular, an instance of the label-efficient learning problem\cite{cesabianchi05minimizing}.
%Cesa-Bianchi et al.~\cite{cesabianchi06regret} show that in the online setting, the regret of a partial monitoring game is lower bounded by $O(T^{2/3})$, where $T$ is the number of examples seen. They also provide an algorithm that meets this bound: use the current model to pick the best label and query for complete labels at random with a small probability to update your model.
%These guarantees provide theoretical foundation for our work.

% We already discussed expectimin trees in the relevant section.
%\paragraph{Expectimin trees and game playing}
%Monte Carlo based search methods~\cite{browne2012monte} are a common solution for finding a policy for an expectimin tree.
%Our usage is slightly different in that we do not need to explore infinite depth.
%Monte Carlo tree search can be extended to continuous state spaces using progressive widening.
%However, because so much information is shared across time, we propose a slight modification of the Dyna-2\cite{silver2008sample} algorithm which proposes features for a linear state value function.
%we do not use separate local features because our
%- Using state has been explored in Dyna-2 - we do not use a separate set of local features because the state space isn't sufficiently different.
